{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time \n",
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.infer as infer\n",
    "from pyro.contrib.examples.util import get_data_loader, get_data_directory\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "# def train(args, train_loader, gpmodule, optimizer, loss_fn, epoch):\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         if args.cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         if args.binary:\n",
    "#             target = (target % 2).float()\n",
    "        \n",
    "#         gpmodule.set_data(data, target)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = loss_fn(gpmodule.model, gpmodule.guide)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         batch_idx = batch_idx + 1\n",
    "#         if batch_idx % args.log_interval == 0:\n",
    "#             print(\"Train Epoch: {:2d} [{:5d}/{} ({:2.0f}%)]\\tLoss: {:.6f}\"\n",
    "#                   .format(epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                           100. * batch_idx / len(train_loader), loss))\n",
    "\n",
    "# def test(args, test_loader, gpmodule):\n",
    "#     correct = 0\n",
    "#     for data, target in test_loader:\n",
    "#         if args.cuda:\n",
    "#             data, target = data.cuda(), target.cuda()\n",
    "#         if args.binary:\n",
    "#             target = (target % 2).float()\n",
    "            \n",
    "#         # get prediction of gp model on new data\n",
    "#         f_loc, f_var = gpmodule(data)\n",
    "#         # use its likehood to give prediction class\n",
    "#         pred = gpmodule.likelihood(f_loc, f_var)\n",
    "#         # compare prediction and target to count accuaracy\n",
    "#         correct += pred.eq(target).long().cpu().sum().item()\n",
    "        \n",
    "#     print(\"\\nTest set: Accuracy: {}/{} ({:.2f}%)\\n\"\n",
    "#           .format(correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "# def main(args):\n",
    "#     data_dir = args.data_dir if args.data_dir is not None else get_data_directory(__file__)\n",
    "#     train_loader = get_data_loader(dataset_name = 'MNIST',\n",
    "#                                    data_dir = data_dir,\n",
    "#                                    batch_size = args.batch_size,\n",
    "#                                    dataset_transforms = [transforms.Normalize((0.1307,), (0.3081,))],\n",
    "#                                    is_training_set=True,\n",
    "#                                    shuffle=True)\n",
    "#     test_loader = det_data_loader(dataset_name = 'MNIST',\n",
    "#                                   data_dir = data_dir,\n",
    "#                                   batch_size = args.test_batch_size,\n",
    "#                                   dataset_transforms = [transforms.Normalize((0.1307,), (0.3081,))],\n",
    "#                                   is_training_set = False,\n",
    "#                                   shuffle=False)\n",
    "#     if args.cuda:\n",
    "#         train_loader.num_workers = 1\n",
    "#         test_loader.num_workers = 1\n",
    "    \n",
    "#     cnn = CNN()\n",
    "    \n",
    "#     # create deep kernel by warping RBF with CNN\n",
    "#     # CNN will transform a high dimension image into a low dimension 2D tensors for RBF kernel\n",
    "#     # This kernel accepts inputs of CNN and gives outputs are coveriance matrix of RBF\n",
    "#     # on output of CNN\n",
    "    \n",
    "#     rbf = gp.kernels.RBF(input_dim = 10, lengthscale=torch.ones(10))\n",
    "#     deep_kernel  = gp.kernels.Warping(rdf, iwarping_fn=cnn)\n",
    "    \n",
    "    \n",
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = gp.kernels.RBF(input_dim = 2, lengthscale=torch.ones(10))\n",
    "print(rbf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
