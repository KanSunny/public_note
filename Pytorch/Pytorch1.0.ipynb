{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 1.0 tutorials\n",
    "_have a basic familiarity of pytorch 0.3, according to https://pytorch.org/tutorials/_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up cuda or non-cuda versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use anaconda3 and conda to setup pytorch.  \n",
    "And it is very slow to download pytorch from pytorch.org. Therefore, we use https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/linux-64/ to make it.  \n",
    "Sellect and  download corresponding version from aforementsion url and \"conda install it\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is pytorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use standard NumPy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    140143715670560,                  24],\n",
      "        [    140144782868479, 8171062582517395298],\n",
      "        [8243662592152856949, 7310305785198503009]])\n",
      "tensor([    140143715670560,     140144782868479, 8243662592152856949])\n",
      "tensor([140143715670560,              24])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test = torch.empty(3,2,dtype=torch.long)\n",
    "print(test)\n",
    "print(test[:, 0]) # select the 0 column or the first one from secondth dimension\n",
    "print(test[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you have a one element tensor, use .item() to get the value as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1207])\n",
      "-1.120747447013855\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors can be moved onto any device using the .to method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1207], device='cuda:0')\n",
      "tensor([-0.1207], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device = device) # directly create a tensor on gpu\n",
    "    x = x.to(device)\n",
    "    \n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\" , torch.double)) # \".to\" also can change dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Automatic differentitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different from pytorch 0.3: there have no variable, torch has autograd  \n",
    ".backward : backward this result  \n",
    ".grad : compute this grad\n",
    "$a.backward + b.grad \\Leftarrow \\Rightarrow \\frac{d(a)}{d(b)} $  \n",
    "you can use the .grad_fn to check the compute graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.]])\n",
      "tensor([[3., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "x = torch.Tensor([1, 2]) # 1 dimension vector\n",
    "# use unsquence to 2 dimension vector(raw or column)\n",
    "x.unsqueeze_(0)\n",
    "x.resize_(2,2)\n",
    "x[1, :] = 1\n",
    "\n",
    "# init parameter\n",
    "w = torch.zeros(2,1).t_() # 2 dimension raw vector\n",
    "w.requires_grad_(True) # you must give the leaf parameter, the parameter in NN is leaf\n",
    "\n",
    "for i in range(2):\n",
    "    items = x[:, i]\n",
    "    items.unsqueeze_(1)\n",
    "    result = w.mm(items)\n",
    "    \n",
    "    result.backward() # result = w.mm(x), so \\farc{d(result)}{d(w)} = x\n",
    "    print(w.grad) # w.grad = w.grad_origin + w.grad_new = [1,1]+[2,1], you need tor zero_grad it to check each grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use any of the \"Tensor operations\" in the forward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# you should tranfer the nn, inputs and targets onto GPU\n",
    "net.to(device)\n",
    "inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on multiple Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model) # according the number of gpus to change the dimension of nn\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
